{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "**Dimensionality Reduction** is the process of reducing the number of dimensions/ variables in the data, when there are too many features to analyze.\n",
    "\n",
    "**Principal Components** are unit vectors or new variables that are constructed as linear combinations of the initial variables.\n",
    "\n",
    "These combinations are done in such a way that the principal components are uncorrelated and most of the information within the inital variables is compressed into the first components. We project each data point onto only the first few principal components to obtain lower-dimensional data while preserving as much data variation as possible.\n",
    "\n",
    "![pca](./files/pca1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "1. Data Standardization `(x = (x - mean) / sd)`\n",
    "2. Compute the covariance matrix (To analyze the correlation between the variables)\n",
    "3. Compute the eigenvalues and eigenvectors of the covariance matrix (scaling factors and transformation vectors)\n",
    "4. Rearrange the eigenvalues and eigenvectors (in the order of decreasing eigenvalue)\n",
    "5. Compute the cumulative energy content of each eigenvector (optional)\n",
    "6. Select a subset of eigenvectors as the basis vectors\n",
    "7. Project the data onto the new basis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
